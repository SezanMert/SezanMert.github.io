---
layout: archive
title: "Real/Video Action Perception EEG Project"
permalink: /eegproject/
author_profile: false
---

## Understanding the Differences between Real and Video Action Perception under Attentional Load

The actions we see in real life possess many features that are left out in Point-Light-Displays. One of these essential features is actability: we usually respond to the actions we see in real life. To understand the differences between real-life actions and video actions under attentional load conditions, we will conduct an EEG study using a novel setup of a transparent screen. While this setup was built, we collected some EEG data with only video actions. I coded this pilot experiment with PsychoPy on Python and collected data from 3 participants. Now, I am analysing it using EEGLAB on MATLAB.

<table style="border-collapse: collapse; border: none;">
<tr style="border: none; height: 200px;">
  <td style="border: none;"><img src="/images/setup.jpg" alt="setup.png" width="150" height="200" /></td>
  <td  style="border: none;"><img src="/images/eegthesis.gif" alt="eegthesis.png" width="400" height="200" /></td>  
  <td  style="border: none;"><img src="/images/data_collection.jpg" alt="data_collection.jpg" width="200" height="200" /></td>  
</tr>
  <tr style="border: none; height: 200px;">
    <td style="border: none;" width="150">
      <a href="https://www.jove.com/t/65436/a-naturalistic-setup-for-presenting-real-people-live-actions">
      <font style="font-size: 1.2vw;" >T. N. Pekçetin, Ş. Evsen, S. Pekçetin, C. Acarturk, B. A. Ürgen (2023)</font></a>
    </td>
    <td style="border: none;" width="400"></td>
    <td style="border: none;" width="200"></td>
  </tr>
</table>
