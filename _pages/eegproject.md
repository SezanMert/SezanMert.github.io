---
layout: archive
title: "Real/Video Action Perception EEG Project"
permalink: /eegproject/
author_profile: false
---

## Understanding the Differences between Real and Video Action Perception under Attentional Load

The actions we see in real life possess many features that are left out in Point-Light-Displays. One of these essential features is actability: we usually respond to the actions we see in real life. To understand the differences between real-life actions and video actions under attentional load conditions, we will conduct an EEG study using a novel setup of a transparent screen. While this setup was built, we collected some EEG data with only video actions. I coded this pilot experiment with PsychoPy on Python and collected data from 3 participants. Now, I am analysing it using EEGLAB on MATLAB.

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none; height: 200px;">
  <td style="border: none;"><img src="/images/setup.jpg" alt="setup.png" width="600" height="800" /></td>
  <td  style="border: none;"><img src="/images/eegthesis.gif" alt="eegthesis.png" width="400" height="200" /></td>  
  <td  style="border: none;"><img src="/images/data_collection.jpg" alt="data_collection.jpg" width="600" height="600" /></td>  
</tr>


